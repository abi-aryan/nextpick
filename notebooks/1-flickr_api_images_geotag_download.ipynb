{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import secrets\n",
    "import flickrapi\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "\n",
    "def get_photos(image_tag):\n",
    "\n",
    "    # setup dataframe for data\n",
    "    raw_photos = pd.DataFrame(columns=['latitude', 'longitude','farm','server','id','secret'])\n",
    "    \n",
    "    # initialize api\n",
    "    flickr = flickrapi.FlickrAPI(secrets.api_key, secrets.api_secret, format='parsed-json')\n",
    "\n",
    "    errors = ''\n",
    "    try:\n",
    "        # search photos based on settings\n",
    "        photos = flickr.photos.search(tags=image_tag,\n",
    "                                      sort='relevance',\n",
    "                                      content_type=1,            #photos only\n",
    "                                      extras='description,geo,url_c',\n",
    "                                      has_geo=1,\n",
    "                                      geo_context=2,             #outdoors\n",
    "                                      per_page=100,\n",
    "                                      page=1\n",
    "                                      )\n",
    "\n",
    "        # append photo details: description and getags\n",
    "        raw_photos = raw_photos.append(pd.DataFrame(photos['photos']['photo'])\n",
    "                                       [['latitude', 'longitude','farm','server','id','secret']],\n",
    "                                       ignore_index=True)\n",
    "\n",
    "        # construct url from pieces\n",
    "        raw_photos['url'] = 'https://farm'+ raw_photos.farm.astype(str) + '.staticflickr.com/' + raw_photos.server.astype(str) + '/'+ raw_photos.id.astype(str) + '_' + raw_photos.secret.astype(str) + '.jpg'\n",
    "                    \n",
    "        # need a try/except here for images less than 'per page'\n",
    "        print('..downloading photos')\n",
    "        download_images(raw_photos, image_tag)\n",
    "        \n",
    "        # save data\n",
    "        print('..saving metadata')\n",
    "        with open('data/%s/%s.pkl' %(image_tag, image_tag), 'wb') as f:\n",
    "            pickle.dump(raw_photos, f)\n",
    "            f.close()\n",
    "            \n",
    "        del raw_photos\n",
    "        \n",
    "    except:\n",
    "        print('Could not get info for: %s. '%image_tag)\n",
    "        errors = image_tag\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "def create_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def download_images(df, keyword):\n",
    "    path = ''.join(['data/',keyword])\n",
    "    create_folder(path)\n",
    "\n",
    "    print('...df length: %d' %len(df.index))\n",
    "    print('...going through each row of dataframe')\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            image_path = ''.join([path,'/',row.id,'.jpg'])\n",
    "            response = requests.get(row.url)#, stream=True)\n",
    "\n",
    "            with open(image_path, 'wb') as outfile:\n",
    "                outfile.write(response.content)\n",
    "                outfile.close()\n",
    "                \n",
    "        except:\n",
    "            print('...Error occured at idx: %d'%idx)\n",
    "\n",
    "    print('...download completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv('IndoorOutdoor_places205.csv', names=['key','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/a/abbey'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/a/airport_terminal'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/a/alley'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/a/amphitheater'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/a/amusement_park'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    key  label\n",
       "0             /a/abbey'      2\n",
       "1  /a/airport_terminal'      1\n",
       "2             /a/alley'      2\n",
       "3      /a/amphitheater'      2\n",
       "4    /a/amusement_park'      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbey</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alley</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amphitheater</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amusement park</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aqueduct</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>skyscraper</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>slum</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>snowfield</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>swamp</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>stadium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                key  label\n",
       "0             abbey      2\n",
       "1             alley      2\n",
       "2      amphitheater      2\n",
       "3    amusement park      2\n",
       "4          aqueduct      2\n",
       "..              ...    ...\n",
       "107      skyscraper      2\n",
       "108            slum      2\n",
       "109       snowfield      2\n",
       "110           swamp      2\n",
       "111         stadium      2\n",
       "\n",
       "[112 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve all outdoor scene categories. We clean up the 'key' column, remove duplicates, and re-index the dataframe.\n",
    "places['key'] = places['key'].str[3:].str.split('/',1,expand=True)\n",
    "places = places[places.label == 2]\n",
    "places = places.drop_duplicates(ignore_index=True)\n",
    "places['key'] = places['key'].str.strip('\\'')\n",
    "places['key'] = places['key'].replace(to_replace='_',value=' ',regex=True)\n",
    "places.head(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key      132\n",
       "label    132\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places.count() #should have 132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               abbey in 1.23e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               alley in 1.18e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "        amphitheater in 1.27e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "      amusement park in 1.28e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            aqueduct in 1.29e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                arch in 1.47e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "  apartment building in 1.33e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            badlands in 1.21e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "       bamboo forest in 1.22e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "      baseball field in 1.23e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 22\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            basilica in 2.28e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               bayou in 1.21e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 75\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           boardwalk in 1.53e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 56\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           boat deck in 7.77e+00 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "    botanical garden in 1.16e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              bridge in 1.18e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "     building facade in 1.32e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               butte in 1.40e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            campsite in 1.74e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              canyon in 1.48e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              castle in 1.64e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            cemetery in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              chalet in 1.61e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 13\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               coast in 2.25e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "   construction site in 1.61e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          corn field in 1.60e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "      cottage garden in 1.63e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          courthouse in 1.59e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 55\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           courtyard in 1.53e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               creek in 1.62e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            crevasse in 1.57e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           crosswalk in 1.70e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           cathedral in 1.56e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              church in 1.61e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                 dam in 1.55e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                dock in 1.47e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            driveway in 1.46e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              desert in 1.46e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             doorway in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 43\n",
      "...Error occured at idx: 44\n",
      "...Error occured at idx: 82\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          excavation in 2.66e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             fairway in 1.36e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         fire escape in 1.51e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "        fire station in 1.98e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         forest path in 2.50e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         forest road in 1.58e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "       formal garden in 1.45e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            fountain in 1.42e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               field in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "        garbage dump in 1.59e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 99\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         gas station in 1.55e+01 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         golf course in 1.58e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 15\n",
      "...Error occured at idx: 91\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              harbor in 2.03e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         herb garden in 1.77e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             highway in 1.68e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 58\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            hospital in 2.14e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 36\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          hot spring in 2.58e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               hotel in 1.50e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             iceberg in 1.38e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 8\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               igloo in 2.91e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 70\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               islet in 2.22e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "    ice skating rink in 1.54e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                 inn in 1.63e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              kasbah in 1.62e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          lighthouse in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             mansion in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               marsh in 1.40e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           mausoleum in 1.61e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              medina in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 99\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               motel in 1.51e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            mountain in 1.53e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 1\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "      mountain snowy in 3.15e-01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              market in 1.50e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           monastery in 1.38e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               ocean in 1.48e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "     office building in 1.48e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             orchard in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              pagoda in 1.50e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              palace in 1.61e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         parking lot in 1.48e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             pasture in 1.68e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 49\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               patio in 2.14e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            pavilion in 1.53e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         phone booth in 1.51e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 64\n",
      "...Error occured at idx: 65\n",
      "...Error occured at idx: 95\n",
      "...Error occured at idx: 98\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         picnic area in 2.10e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          playground in 1.51e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               plaza in 1.43e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                pond in 1.42e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          racecourse in 1.37e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 62\n",
      "...Error occured at idx: 63\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                raft in 1.87e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "      railroad track in 1.44e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 76\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          rainforest in 2.00e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "residential neighborhood in 1.54e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 18\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "    restaurant patio in 3.07e+00 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          rice paddy in 1.40e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               river in 1.54e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           rock arch in 1.48e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         rope bridge in 1.72e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                ruin in 1.73e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...download completed.\n",
      "..saving metadata\n",
      "              runway in 1.56e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             sandbar in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         schoolhouse in 1.85e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           sea cliff in 1.53e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 42\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                shed in 2.33e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           shopfront in 1.50e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          ski resort in 1.51e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           ski slope in 1.39e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                 sky in 1.41e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          skyscraper in 1.44e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                slum in 1.59e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           snowfield in 1.75e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               swamp in 1.46e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             stadium in 1.53e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "       swimming pool in 1.55e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 77\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "      topiary garden in 1.47e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               tower in 1.62e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 53\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "       train railway in 9.02e+00 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           tree farm in 1.47e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 4\n",
      "...Error occured at idx: 76\n",
      "...Error occured at idx: 93\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              trench in 3.25e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              temple in 1.40e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "               track in 1.57e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 28\n",
      "...Error occured at idx: 50\n",
      "...download completed.\n",
      "..saving metadata\n",
      "          underwater in 9.47e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "              valley in 1.28e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 3\n",
      "...download completed.\n",
      "..saving metadata\n",
      "    vegetable garden in 3.62e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             veranda in 1.56e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             viaduct in 1.55e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "             volcano in 1.52e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         water tower in 1.67e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 4\n",
      "...download completed.\n",
      "..saving metadata\n",
      "       watering hole in 3.30e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "         wheat field in 1.47e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 41\n",
      "...download completed.\n",
      "..saving metadata\n",
      "           wind farm in 2.29e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...download completed.\n",
      "..saving metadata\n",
      "            windmill in 1.59e+01 seconds.\n",
      "..downloading photos\n",
      "...df length: 100\n",
      "...going through each row of dataframe\n",
      "...Error occured at idx: 34\n",
      "...download completed.\n",
      "..saving metadata\n",
      "                yard in 2.41e+01 seconds.\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for idx, row in places.iterrows():\n",
    "\n",
    "    # change this idx when it crashes. It will give an error for a few indices. It probably means Flickr does not have \n",
    "    # geotagged images for these keywords. We skip over those. Should have a total of 130 keywords at the end.\n",
    "    if idx < 0:\n",
    "        pass\n",
    "    else:\n",
    "        start = time()\n",
    "        error = get_photos(row.key)\n",
    "        end = time()\n",
    "        print('%20s in %.2e seconds.' %(row.key, end-start)) # should vary between 3-8 seconds depending on the keyword.\n",
    "        \n",
    "        if error != '':\n",
    "            errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we test loading the pickle file.\n",
    "keyword = 'basilica'\n",
    "with open('data/%s/%s.pkl' %(keyword,keyword), 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>farm</th>\n",
       "      <th>server</th>\n",
       "      <th>id</th>\n",
       "      <th>secret</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.006141</td>\n",
       "      <td>28.977330</td>\n",
       "      <td>66</td>\n",
       "      <td>65535</td>\n",
       "      <td>49957630107</td>\n",
       "      <td>74482549bd</td>\n",
       "      <td>https://farm66.staticflickr.com/65535/49957630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.902261</td>\n",
       "      <td>12.453346</td>\n",
       "      <td>66</td>\n",
       "      <td>65535</td>\n",
       "      <td>49946502777</td>\n",
       "      <td>a97fc528b6</td>\n",
       "      <td>https://farm66.staticflickr.com/65535/49946502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.416493</td>\n",
       "      <td>12.201175</td>\n",
       "      <td>66</td>\n",
       "      <td>65535</td>\n",
       "      <td>49937948567</td>\n",
       "      <td>af566914f8</td>\n",
       "      <td>https://farm66.staticflickr.com/65535/49937948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.009966</td>\n",
       "      <td>28.978080</td>\n",
       "      <td>66</td>\n",
       "      <td>65535</td>\n",
       "      <td>49935911456</td>\n",
       "      <td>5b2d72ea0a</td>\n",
       "      <td>https://farm66.staticflickr.com/65535/49935911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.067085</td>\n",
       "      <td>12.625565</td>\n",
       "      <td>66</td>\n",
       "      <td>65535</td>\n",
       "      <td>49916045253</td>\n",
       "      <td>f49219b8ca</td>\n",
       "      <td>https://farm66.staticflickr.com/65535/49916045...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude  longitude farm server           id      secret  \\\n",
       "0  41.006141  28.977330   66  65535  49957630107  74482549bd   \n",
       "1  41.902261  12.453346   66  65535  49946502777  a97fc528b6   \n",
       "2  44.416493  12.201175   66  65535  49937948567  af566914f8   \n",
       "3  41.009966  28.978080   66  65535  49935911456  5b2d72ea0a   \n",
       "4  43.067085  12.625565   66  65535  49916045253  f49219b8ca   \n",
       "\n",
       "                                                 url  \n",
       "0  https://farm66.staticflickr.com/65535/49957630...  \n",
       "1  https://farm66.staticflickr.com/65535/49946502...  \n",
       "2  https://farm66.staticflickr.com/65535/49937948...  \n",
       "3  https://farm66.staticflickr.com/65535/49935911...  \n",
       "4  https://farm66.staticflickr.com/65535/49916045...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we test loading the image.\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('data/%s/%s.jpg'%(keyword,test.id[0]))\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
