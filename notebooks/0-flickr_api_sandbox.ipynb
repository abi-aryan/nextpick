{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import flickrapi\n",
    "import logging\n",
    "from helper import get_urls\n",
    "from helper import download_images\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import flickrapi\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_photos(image_tag):\n",
    "\n",
    "    raw_photos = pd.DataFrame(columns=['description', 'latitude', 'longitude'])\n",
    "\n",
    "    flickr = flickrapi.FlickrAPI(config.api_key, config.api_secret, format='parsed-json')\n",
    "    # photos = flickr.walk(text=image_tag,        # it will search by image title and image tags\n",
    "    #                      extras='url_c',     # get the urls for each size we want\n",
    "    #                      privacy_filter=1,   # search only for public photos\n",
    "    #                      per_page=50,\n",
    "    #                      sort='relevance')   # we want what we are looking for to appear first\n",
    "    #\n",
    "\n",
    "    photos = flickr.photos.search(tags=image_tag,\n",
    "                                  extras='description,geo',\n",
    "                                  has_geo = 1\n",
    "                                  )\n",
    "    raw_photos = raw_photos.append(pd.DataFrame(photos['photos']['photo'])\n",
    "                                   [['description', 'latitude', 'longitude']],\n",
    "                                   ignore_index=True)\n",
    "    with open('test.pkl', 'wb') as f:\n",
    "        pickle.dump(raw_photos, f)\n",
    "\n",
    "    return photos\n",
    "\n",
    "\n",
    "def get_urls(image_tag, max):\n",
    "    photos = get_photos(image_tag)\n",
    "    counter = 0\n",
    "    urls = []\n",
    "\n",
    "    for photo in photos:\n",
    "        if counter < max:\n",
    "            url = photo.get('url_c')\n",
    "            if url:\n",
    "                urls.append(url)\n",
    "                counter += 1\n",
    "            # if no url for the desired sizes then try with the next photo\n",
    "        else:\n",
    "            break\n",
    "    return urls\n",
    "\n",
    "\n",
    "def create_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def download_images(urls, path):\n",
    "    create_folder(path)\n",
    "    total = 0\n",
    "\n",
    "    for url in urls:\n",
    "        image_name = str(total).zfill(6) + '.jpg'\n",
    "        image_path = os.path.join(path, image_name)\n",
    "\n",
    "        if not os.path.isfile(image_path):  # ignore if already downloaded\n",
    "            response = requests.get(url, stream=True)\n",
    "\n",
    "            with open(image_path, 'wb') as outfile:\n",
    "                outfile.write(response.content)\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    logging.info('download completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'camping'\n",
    "get_photos(keyword)\n",
    "with open('test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'beach'\n",
    "max_num = 20\n",
    "urls = get_urls(keyword, max_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 3.45e+00 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "download_images(urls, \"data/%s\" %keyword)\n",
    "end = time()\n",
    "\n",
    "print('Completed in %.2e seconds.' %(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
